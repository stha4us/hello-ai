{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6561c60",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "jupyter nbextension enable --py widgetsnbextension --sys-prefix \n",
    "jupyter nbextension install --py --symlink tensorflow_model_analysis --sys-prefix \n",
    "jupyter nbextension enable --py tensorflow_model_analysis --sys-prefix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42673e14",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Upgrade pip to the latest version and install required packages\n",
    "!pip install -U pip\n",
    "!pip install --use-deprecated=legacy-resolver tensorflow_data_validation==1.1.0\n",
    "!pip install --use-deprecated=legacy-resolver tensorflow-transform==1.0.0\n",
    "!pip install --use-deprecated=legacy-resolver tensorflow-model-analysis==0.32.0\n",
    "!pip install apache-beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0d6912",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Checking the installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcd7ca3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import packages and print versions\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_analysis as tfma\n",
    "import tensorflow_data_validation as tfdv\n",
    "\n",
    "print('TF version: {}'.format(tf.__version__))\n",
    "print('TFMA version: {}'.format(tfma.__version__))\n",
    "print('TFDV version: {}'.format(tfdv.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e66a73",
   "metadata": {},
   "source": [
    "Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18493395",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# String variables for file and directory names\n",
    "URL = 'path to file.tar.gz'\n",
    "TAR_NAME = 'C3_W4_Lab_1_starter_files.tar.gz'\n",
    "BASE_DIR = 'starter_files'\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
    "CSV_DIR = os.path.join(DATA_DIR, 'csv')\n",
    "TFRECORD_DIR = os.path.join(DATA_DIR, 'tfrecord')\n",
    "MODELS_DIR = os.path.join(BASE_DIR, 'models')\n",
    "SCHEMA_FILE = os.path.join(BASE_DIR, 'schema.pbtxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d1ae67",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# uncomment this line if you've downloaded the files before and want to reset\n",
    "# !rm -rf {BASE_DIR}\n",
    "\n",
    "# Download the tar file from GCP\n",
    "!wget {URL}\n",
    "\n",
    "# Extract the tar file to the base directory\n",
    "!tar xzf {TAR_NAME}\n",
    "\n",
    "# Delete tar file\n",
    "!rm {TAR_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4392fb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Here's what we downloaded:\")\n",
    "!ls {BASE_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28ed303",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Preview the dataset\n",
    "# Path to the full test set\n",
    "TEST_DATA_PATH = os.path.join(CSV_DIR, 'data_test.csv')\n",
    "\n",
    "# Preview the first few rows\n",
    "!head {TEST_DATA_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e06968",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load the schema as a protocol buffer\n",
    "SCHEMA = tfdv.load_schema_text(SCHEMA_FILE)\n",
    "\n",
    "# Display the schema\n",
    "tfdv.display_schema(SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966a9536",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# imports for helper function\n",
    "import csv\n",
    "from tensorflow.core.example import example_pb2\n",
    "from tensorflow_metadata.proto.v0 import schema_pb2\n",
    "\n",
    "def csv_to_tfrecord(schema, csv_file, tfrecord_file):\n",
    "  ''' Converts a csv file into a tfrecord\n",
    "  Args:\n",
    "    schema (schema_pb2) - Schema protobuf from TFDV\n",
    "    csv_file (string) - file to convert to tfrecord\n",
    "    tfrecord_file (string) - filename of tfrecord to create\n",
    "\n",
    "  Returns:\n",
    "    filename of tfrecord\n",
    "  '''\n",
    "\n",
    "  # Open CSV file for reading. Each row is mapped as a dictionary.\n",
    "  reader = csv.DictReader(open(csv_file, 'r'))\n",
    "  \n",
    "  # Initialize TF examples list\n",
    "  examples = []\n",
    "\n",
    "  # For each row in CSV, create a TF Example based on\n",
    "  # the Schema and append to the list\n",
    "  for line in reader:\n",
    "\n",
    "    # Intialize example\n",
    "    example = example_pb2.Example()\n",
    "\n",
    "    # Loop through features in the schema\n",
    "    for feature in schema.feature:\n",
    "\n",
    "      # Get current feature name\n",
    "      key = feature.name\n",
    "\n",
    "      # Populate values based on data type of current feature\n",
    "      if feature.type == schema_pb2.FLOAT:\n",
    "        example.features.feature[key].float_list.value[:] = (\n",
    "            [float(line[key])] if len(line[key]) > 0 else [])\n",
    "      elif feature.type == schema_pb2.INT:\n",
    "        example.features.feature[key].int64_list.value[:] = (\n",
    "            [int(line[key])] if len(line[key]) > 0 else [])\n",
    "      elif feature.type == schema_pb2.BYTES:\n",
    "        example.features.feature[key].bytes_list.value[:] = (\n",
    "            [line[key].encode('utf8')] if len(line[key]) > 0 else [])\n",
    "        \n",
    "    # Append to the list\n",
    "    examples.append(example)\n",
    "\n",
    "  # Write examples to tfrecord file\n",
    "  with tf.io.TFRecordWriter(tfrecord_file) as writer:\n",
    "    for example in examples:\n",
    "      writer.write(example.SerializeToString())\n",
    "  \n",
    "  return tfrecord_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ad65cf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create tfrecord directory\n",
    "!mkdir {TFRECORD_DIR}\n",
    "\n",
    "# Create list of tfrecord files\n",
    "tfrecord_files = [csv_to_tfrecord(SCHEMA, f'{CSV_DIR}/{name}', f\"{TFRECORD_DIR}/{name.replace('csv','tfrecord')}\") \n",
    "  for name in os.listdir(CSV_DIR)]\n",
    "\n",
    "# Print created files\n",
    "print(f'files created: {tfrecord_files}')\n",
    "\n",
    "# Create variables for each tfrecord\n",
    "TFRECORD_FULL = os.path.join(TFRECORD_DIR, 'data_test.tfrecord')\n",
    "TFRECORD_DAY1 = os.path.join(TFRECORD_DIR, 'data_test_1.tfrecord')\n",
    "TFRECORD_DAY2 = os.path.join(TFRECORD_DIR, 'data_test_2.tfrecord')\n",
    "TFRECORD_DAY3 = os.path.join(TFRECORD_DIR, 'data_test_3.tfrecord')\n",
    "\n",
    "# Delete unneeded variable\n",
    "del tfrecord_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f876f5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# list model directories\n",
    "!ls {MODELS_DIR}\n",
    "\n",
    "# Create string variables for each model directory\n",
    "MODEL1_FILE = os.path.join(MODELS_DIR, 'model1')\n",
    "MODEL2_FILE = os.path.join(MODELS_DIR, 'model2')\n",
    "MODEL3_FILE = os.path.join(MODELS_DIR, 'model3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabde848",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load model 1\n",
    "model = tf.keras.models.load_model(MODEL1_FILE)\n",
    "\n",
    "# Print summary. You can ignore the warnings at the start.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0018241c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Transformation layer can be accessed in two ways. These are equivalent.\n",
    "model.get_layer('transform_features_layer') is model.tft_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caacb68",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "\n",
    "# Load one tfrecord\n",
    "tfrecord_file = tf.data.TFRecordDataset(TFRECORD_DAY1)\n",
    "\n",
    "# Parse schema object as a feature spec\n",
    "feature_spec = schema_utils.schema_as_feature_spec(SCHEMA).feature_spec\n",
    "\n",
    "# Create a batch from the dataset\n",
    "for records in tfrecord_file.batch(1).take(1):\n",
    "\n",
    "  # Parse the batch to get a dictionary of raw features\n",
    "  parsed_examples = tf.io.parse_example(records, feature_spec)\n",
    "\n",
    "  # Print the results\n",
    "  print(\"\\nRAW FEATURES:\")\n",
    "  for key, value in parsed_examples.items():\n",
    "    print(f'{key}: {value.numpy()}')\n",
    "  \n",
    "  # Pop the label since the model does not expect a label input\n",
    "  parsed_examples.pop('label')\n",
    "\n",
    "  # Transform the rest of the raw features using the transform layer\n",
    "  transformed_examples = model.tft_layer(parsed_examples)\n",
    "\n",
    "  # Print the input to the model\n",
    "  print(\"\\nTRANSFORMED FEATURES:\")\n",
    "  for key, value in transformed_examples.items():\n",
    "    print(f'{key}: {value.numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3950440",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "\n",
    "# Load one tfrecord\n",
    "tfrecord_file = tf.data.TFRecordDataset(TFRECORD_DAY1)\n",
    "\n",
    "# Parse schema object as a feature spec\n",
    "feature_spec = schema_utils.schema_as_feature_spec(SCHEMA).feature_spec\n",
    "\n",
    "# Create a batch from the dataset\n",
    "for records in tfrecord_file.batch(5).take(1):\n",
    "\n",
    "  # Get the label values from the raw input\n",
    "  parsed_examples = tf.io.parse_example(records, feature_spec)\n",
    "  y_true = parsed_examples.pop('label')\n",
    "  print(f'labels:\\n {y_true.numpy()}\\n')\n",
    "  \n",
    "  # Transform the raw features and pass to the model to get predictions\n",
    "  transformed_examples = model.tft_layer(parsed_examples)\n",
    "  y_pred = model(transformed_examples)\n",
    "  print(f'predictions:\\n {y_pred.numpy()}\\n')\n",
    "  \n",
    "  # Measure the binary accuracy\n",
    "  metric = tf.keras.metrics.BinaryAccuracy(threshold=0.3)\n",
    "  metric.update_state(y_true, y_pred)\n",
    "  print(f'binary accuracy: {metric.result().numpy()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e63a9f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load one tfrecord\n",
    "tfrecord_file = tf.data.TFRecordDataset(TFRECORD_DAY1)\n",
    "\n",
    "# Print available signatures\n",
    "print(f'model signatures: {model.signatures}\\n')\n",
    "\n",
    "# Create a batch\n",
    "for records in tfrecord_file.batch(5).take(1):\n",
    "\n",
    "  # Pass the batch to the model serving signature to get predictions\n",
    "  output = model.signatures['serving_default'](examples=records)\n",
    "\n",
    "  # Print results\n",
    "  print(f\"predictions:\\n {output['output_0']}\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
